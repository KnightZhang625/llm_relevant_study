raw_data_path: /home/jiaxijzhang/llm_relevant_study/dataset/llm_router_dataset-synth

model_name_or_path: /nfs1/jiaxinzhang/models/ModernBERT-large
model_max_length: 512

output_dir: "/nfs1/jiaxinzhang/saved_for_checkpoint/bert-classifier"
per_device_train_batch_size: 64
per_device_eval_batch_size: 32
learning_rate: 5.0e-5
num_train_epochs: 3
bf16: true
optim: "adamw_torch_fused"
logging_strategy: "steps"
logging_steps: 1
eval_strategy: "epoch"
save_strategy: "epoch"
save_total_limit: 2
load_best_model_at_end: ture
metric_for_best_model: "f1"     # must be the name of metric returned by compute_metrics
report_to: "wandb"
run_name: "bert-classifier-2"